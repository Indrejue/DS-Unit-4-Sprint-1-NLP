{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science\n",
    "\n",
    "*Unit 4, Sprint 1, Module 3*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification (Prepare)\n",
    "\n",
    "Today's guided module project will be different. You already know how to do classification. You ready know how to extract features from documents. So? That means you're ready to combine and practice those skills in a kaggle competition. We we will open with a five minute sprint explaining the competition, and then give you 25 minutes to work. After those twenty five minutes are up, I will give a 5-minute demo an NLP technique that will help you with document classification (*and **maybe** the competition*).\n",
    "\n",
    "Today's all about having fun and practicing your skills. The competition will begin\n",
    "\n",
    "## Learning Objectives\n",
    "* <a href=\"#p1\">Part 1</a>: Text Feature Extraction & Classification Pipelines\n",
    "* <a href=\"#p2\">Part 2</a>: Latent Semantic Indexing\n",
    "* <a href=\"#p3\">Part 3</a>: Word Embeddings with Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Feature Extraction & Classification Pipelines (Learn)\n",
    "<a id=\"p1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Sklearn pipelines allow you to stitch together multiple components of a machine learning process. The idea is that you can pass you raw data and get predictions out of the pipeline. This ability to pass raw input and receive a prediction from a singular class makes pipelines well suited for production, because you can pickle a a pipeline without worry about other data preprocessing steps. \n",
    "\n",
    "*Note:* Each time we call the pipeline during grid search, each component is fit again. The vectorizer (tf-idf) is transforming our entire vocabulary during each cross-validation fold. That transformation adds significant run time to our grid search. There *might* be interactions between the vectorizer and our classifier, so we estimate their performance together in the code below. However, if your goal is to reduce run time. Train your vectorizer separately (ie out of the grid-searched pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "categories = ['alt.atheism',\n",
    "              'talk.religion.misc']\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From: mangoe@cs.umd.edu (Charley Wingate)\\nSubject: Benediktine Metaphysics\\nLines: 24\\n\\nBenedikt Rosenau writes, with great authority:\\n\\n>     IF IT IS CONTRADICTORY IT CANNOT EXIST.\\n\\n\"Contradictory\" is a property of language.  If I correct this to\\n\\n\\n      THINGS DEFINED BY CONTRADICTORY LANGUAGE DO NOT EXIST\\n\\nI will object to definitions as reality.  If you then amend it to\\n\\n      THINGS DESCRIBED BY CONTRADICTORY LANGUAGE DO NOT EXIST\\n\\nthen we\\'ve come to something which is plainly false.  Failures in\\ndescription are merely failures in description.\\n\\n(I\\'m not an objectivist, remember.)\\n\\n\\n-- \\nC. Wingate        + \"The peace of God, it is no peace,\\n                  +    but strife closed in the sod.\\nmangoe@cs.umd.edu +  Yet, brothers, pray for but one thing:\\ntove!mangoe       +    the marv\\'lous peace of God.\"\\n',\n",
       " 'Subject: Re: There must be a creator! (Maybe)\\nFrom: halat@pooh.bears (Jim Halat)\\nReply-To: halat@pooh.bears (Jim Halat)\\nLines: 24\\n\\nIn article <16BA1E927.DRPORTER@SUVM.SYR.EDU>, DRPORTER@SUVM.SYR.EDU (Brad Porter) writes:\\n>\\n>   Science is wonderful at answering most of our questions.  I\\'m not the type\\n>to question scientific findings very often, but...  Personally, I find the\\n>theory of evolution to be unfathomable.  Could humans, a highly evolved,\\n>complex organism that thinks, learns, and develops truly be an organism\\n>that resulted from random genetic mutations and natural selection?\\n\\n[...stuff deleted...]\\n\\nComputers are an excellent example...of evolution without \"a\" creator.\\nWe did not \"create\" computers.  We did not create the sand that goes\\ninto the silicon that goes into the integrated circuits that go into\\nprocessor board.  We took these things and put them together in an\\ninteresting way. Just like plants \"create\" oxygen using light through \\nphotosynthesis.  It\\'s a much bigger leap to talk about something that\\ncreated \"everything\" from nothing.  I find it unfathomable to resort\\nto believing in a creator when a much simpler alternative exists: we\\nsimply are incapable of understanding our beginnings -- if there even\\nwere beginnings at all.  And that\\'s ok with me.  The present keeps me\\nperfectly busy.\\n\\n-jim halat\\n\\n',\n",
       " 'From: MANDTBACKA@FINABO.ABO.FI (Mats Andtbacka)\\nSubject: Re: An Anecdote about Islam\\nIn-Reply-To: jaeger@buphy.bu.edu\\'s message of 5 Apr 93 16:49:14 GMT\\nOrganization: Unorganized Usenet Postings UnInc.\\nX-News-Reader: VMS NEWS 1.24\\nLines: 24\\n\\nIn <114127@bu.edu> jaeger@buphy.bu.edu writes:\\n\\n[deletia]\\n\\n> I don\\'t understand the point of this petty sarcasm. It is a basic \\n> principle of Islam that if one is born muslim or one says \"I testify\\n> that there is no god but God and Mohammad is a prophet of God\" that,\\n> so long as one does not explicitly reject Islam by word then one _must_\\n> be considered muslim by all muslims. So the phenomenon you\\'re attempting\\n> to make into a general rule or psychology is a direct odds with basic\\n> Islamic principles. If you want to attack Islam you could do better than\\n> than to argue against something that Islam explicitly contradicts.\\n\\n      In the deletions somewhere, it mentioned something about chopping\\noff of hands being a punishment for theft in Saudi Arabia. Assuming this\\nis so (I wouldn\\'t know), and assuming it is done by people fitting your\\nrequirement for \"muslim\" (which I find highly likely), then would you\\nplease try to convince Bobby Mozumder that muslims chop people\\'s hands\\noff?\\n\\n      Come back when you\\'ve succeeded.\\n\\n-- \\n  Disclaimer?   \"It\\'s great to be young and insane!\"\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print out data sample\n",
    "data.data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Pipeline Components\n",
    "\n",
    "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "                 #Vectorizer\n",
    "                 ('vect', vect),\n",
    "                 # Classifier\n",
    "                 ('clf', rfc)\n",
    "                ])\n",
    "\n",
    "# The pipeline puts together a bunch fit then transform,fit then predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__max_df': ( 0.75, 1.0),\n",
    "    'vect__min_df': (2, 10),\n",
    "    'vect__max_features': (500,1000),\n",
    "    'clf__n_estimators': range(10, 101, 10),\n",
    "    'clf__max_depth': range(15, 30, 1)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe,\n",
    "                           parameters,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           verbose=10)\n",
    "X = data.data\n",
    "Y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1200 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:   12.7s\n",
      "[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:   13.8s\n",
      "[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done 433 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 464 tasks      | elapsed:   16.7s\n",
      "[Parallel(n_jobs=-1)]: Done 497 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 530 tasks      | elapsed:   18.9s\n",
      "[Parallel(n_jobs=-1)]: Done 565 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=-1)]: Done 637 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=-1)]: Done 674 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=-1)]: Done 713 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:   26.8s\n",
      "[Parallel(n_jobs=-1)]: Done 793 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:   29.6s\n",
      "[Parallel(n_jobs=-1)]: Done 877 tasks      | elapsed:   30.9s\n",
      "[Parallel(n_jobs=-1)]: Done 920 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:   34.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1010 tasks      | elapsed:   35.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1057 tasks      | elapsed:   37.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1153 tasks      | elapsed:   40.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:   42.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1253 tasks      | elapsed:   44.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1304 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1357 tasks      | elapsed:   47.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1465 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1520 tasks      | elapsed:   53.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1577 tasks      | elapsed:   55.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1634 tasks      | elapsed:   57.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1693 tasks      | elapsed:   59.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1813 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1874 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2000 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2065 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2130 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2197 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2264 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2333 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2402 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2473 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2544 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2617 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2690 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2765 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2840 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2917 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2994 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3073 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3152 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3233 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 3314 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3397 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3480 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3565 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3650 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3737 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3824 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3913 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4002 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4093 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 4184 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4277 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4370 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4465 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4560 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4657 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4754 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4853 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4952 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 5053 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5154 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5257 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 5360 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5465 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 5570 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 5677 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5784 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 5893 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('vect',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 2),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        strip...\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__max_depth': range(15, 30),\n",
       "                         'clf__n_estimators': range(10, 101, 10),\n",
       "                         'vect__max_df': (0.75, 1.0),\n",
       "                         'vect__max_features': (500, 1000),\n",
       "                         'vect__min_df': (2, 10)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9206854345165238"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__max_depth': 29,\n",
       " 'clf__n_estimators': 60,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': 1000,\n",
       " 'vect__min_df': 10}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.predict(['god is the way', 'there is no god'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along \n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model (try using the pipe method I just demoed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "You're trying to achieve 75% Accuracy on your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Indexing (Learn)\n",
    "<a id=\"p2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, # Just here for demo. \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = { \n",
    "    'lsi__svd__n_components': [10,100,250],\n",
    "    'lsi__vect__max_df':[.9, .95, 1.0],\n",
    "    'clf__n_estimators':[5,10,20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSI\n",
    "lsi = Pipeline([('vect', vect), ('svd', svd)])\n",
    "\n",
    "\n",
    "# Pipe\n",
    "pipe = Pipeline([('lsi', lsi), ('clf', rfc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('lsi',\n",
      "                 Pipeline(memory=None,\n",
      "                          steps=[('vect',\n",
      "                                  TfidfVectorizer(analyzer='word', binary=False,\n",
      "                                                  decode_error='strict',\n",
      "                                                  dtype=<class 'numpy.float64'>,\n",
      "                                                  encoding='utf-8',\n",
      "                                                  input='content',\n",
      "                                                  lowercase=True, max_df=1.0,\n",
      "                                                  max_features=None, min_df=1,\n",
      "                                                  ngram_range=(1, 2), norm='l2',\n",
      "                                                  preprocessor=None,\n",
      "                                                  smooth_idf=True,\n",
      "                                                  stop_words='english',\n",
      "                                                  strip_accents=...\n",
      "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
      "                                        class_weight=None, criterion='gini',\n",
      "                                        max_depth=None, max_features='auto',\n",
      "                                        max_leaf_nodes=None, max_samples=None,\n",
      "                                        min_impurity_decrease=0.0,\n",
      "                                        min_impurity_split=None,\n",
      "                                        min_samples_leaf=1, min_samples_split=2,\n",
      "                                        min_weight_fraction_leaf=0.0,\n",
      "                                        n_estimators=100, n_jobs=None,\n",
      "                                        oob_score=False, random_state=None,\n",
      "                                        verbose=0, warm_start=False))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=-1)]: Done 135 out of 135 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('lsi',\n",
       "                                        Pipeline(memory=None,\n",
       "                                                 steps=[('vect',\n",
       "                                                         TfidfVectorizer(analyzer='word',\n",
       "                                                                         binary=False,\n",
       "                                                                         decode_error='strict',\n",
       "                                                                         dtype=<class 'numpy.float64'>,\n",
       "                                                                         encoding='utf-8',\n",
       "                                                                         input='content',\n",
       "                                                                         lowercase=True,\n",
       "                                                                         max_df=1.0,\n",
       "                                                                         max_features=None,\n",
       "                                                                         min_df=1,\n",
       "                                                                         ngram_range=(1,\n",
       "                                                                                      2),\n",
       "                                                                         norm='l2',\n",
       "                                                                         preprocessor=None,\n",
       "                                                                         smooth_...\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators=100,\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'clf__n_estimators': [5, 10, 20],\n",
       "                         'lsi__svd__n_components': [10, 100, 250],\n",
       "                         'lsi__vect__max_df': [0.9, 0.95, 1.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "grid_search = GridSearchCV(pipe,params, cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9101115191078473"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Follow Along\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "4. Make a submission to Kaggle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Continue to apply Latent Semantic Indexing (LSI) to various datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings with Spacy (Learn)\n",
    "<a id=\"p3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Two bananas in pyjamas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "bananas_vector = doc.vector\n",
    "print(len(bananas_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vectors(docs):\n",
    "    return [nlp(doc).vector for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>ratingCategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1321</td>\n",
       "      <td>sometimes when whisky is batched a few leftove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3861</td>\n",
       "      <td>an uncommon exclusive bottling of a 6 year old...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>655</td>\n",
       "      <td>this release is a port version of amrut’s inte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555</td>\n",
       "      <td>this 41 year old single cask was aged in a she...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1965</td>\n",
       "      <td>quite herbal on the nose with aromas of dried ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        description  ratingCategory\n",
       "0  1321  sometimes when whisky is batched a few leftove...               1\n",
       "1  3861  an uncommon exclusive bottling of a 6 year old...               0\n",
       "2   655  this release is a port version of amrut’s inte...               1\n",
       "3   555  this 41 year old single cask was aged in a she...               1\n",
       "4  1965  quite herbal on the nose with aromas of dried ...               1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/Indrejue/DS-Unit-4-Sprint-1-NLP/main/module3-document-classification/Data/train.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/Indrejue/DS-Unit-4-Sprint-1-NLP/main/module3-document-classification/Data/test.csv')\n",
    "\n",
    "def cleaner(df):\n",
    "    df['description'] = df['description'].apply(lambda review: re.sub('(?:[0-9]+/){2}[0-9]{4}','', review))\n",
    "    df['description'] = df['description'].str.lstrip('\\n/')\n",
    "    df['description'] = df['description'].str.strip()\n",
    "    df['description'] = df['description'].apply(lambda review: re.sub('[;.(),!?:\"\"]', '', review))\n",
    "    df['description'] = df['description'].apply(lambda x: x.lower())\n",
    "    return df\n",
    "\n",
    "cleaner(train)\n",
    "cleaner(test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = train['description']\n",
    "X_test_text = test['description']\n",
    "X_train = get_word_vectors(train['description'])\n",
    "X_test = get_word_vectors(test['description'])\n",
    "len(X) == len(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.fit(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.score(X, train['ratingCategory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['ratingCategory'] = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'ratingCategory']].to_csv('testSolutionSubmission.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "What you should be doing now:\n",
    "1. Join the Kaggle Competition\n",
    "2. Download the data\n",
    "3. Train a model & try: \n",
    "    - Creating a Text Extraction & Classification Pipeline\n",
    "    - Tune the pipeline with a `GridSearchCV` or `RandomizedSearchCV`\n",
    "    - Add some Latent Semantic Indexing (lsi) into your pipeline. *Note:* You can grid search a nested pipeline, but you have to use double underscores ie `lsi__svd__n_components`\n",
    "    - Try to extract word embeddings with Spacy and use those embeddings as your features for a classification model.\n",
    "4. Make a submission to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "To review this module: \n",
    "* Continue working on the Kaggle competition\n",
    "* Find another text classification task to work on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
